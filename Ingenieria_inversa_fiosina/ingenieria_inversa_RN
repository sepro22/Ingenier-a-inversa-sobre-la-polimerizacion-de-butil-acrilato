from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler

# Configuraci贸n de estilo para gr谩ficos
plt.style.use('default')
plt.rcParams['font.size'] = 10
plt.rcParams['axes.linewidth'] = 1.0

#  Cargar dataset
df = pd.read_excel("Ingenieria_inversa_fiosina/BD_compuesta_MMD_BA_Mn_Mw.xlsx", sheet_name="compuesta")

# Variables de entrada
X_cols = ['cBA_time', 'Mn', 'Mw'] + [f'MMD{i+1}' for i in range(100)]
X = df[X_cols]

# Variables objetivo
Y_cols = ['cBA_0', 'cAIBN_0', 'temp', 'time']
Y = df[Y_cols]

# ===============================================
# Escalado de datos
# ===============================================
scaler_X = StandardScaler()
X_scaled = scaler_X.fit_transform(X)

scaler_Y = StandardScaler()
Y_scaled = scaler_Y.fit_transform(Y)

# ===============================================
# Divisi贸n entrenamiento / prueba
# ===============================================
X_train, X_test, Y_train, Y_test = train_test_split(
    X_scaled, Y_scaled, test_size=0.2, random_state=42
)

# ===============================================
# Modelo: Red Neuronal Multisalida
# ===============================================
from tensorflow.keras.optimizers import Adam

model = Sequential([
    Dense(256, activation='relu', input_dim=X_train.shape[1]),
    Dropout(0.2),
    Dense(128, activation='relu'),
    Dropout(0.1),
    Dense(64, activation='relu'),
    Dense(4)  # 4 salidas correlacionadas
])

model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')

# Early stopping para evitar sobreajuste
es = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)

history = model.fit(
    X_train, Y_train,
    validation_split=0.2,
    epochs=1000,
    batch_size=32,
    verbose=1,
    callbacks=[es]
)

# ===============================================
# Predicci贸n y desescalado
# ===============================================
Y_pred_scaled = model.predict(X_test)
Y_pred = scaler_Y.inverse_transform(Y_pred_scaled)
Y_test_descaled = scaler_Y.inverse_transform(Y_test)

# ===============================================
# M茅tricas y evaluaci贸n
# ===============================================
mse_global = mean_squared_error(Y_test_descaled, Y_pred)
r2_global = r2_score(Y_test_descaled, Y_pred)
mae_vars = mean_absolute_error(Y_test_descaled, Y_pred, multioutput='raw_values')
r2_vars = r2_score(Y_test_descaled, Y_pred, multioutput='raw_values')

print("\nM茅tricas por variable:")
for i, col in enumerate(Y.columns):
    mae = mae_vars[i]
    try:
        r2 = r2_vars[i]
    except IndexError:
        r2 = np.nan  # por si r2_vars tiene menos elementos
    if not np.isfinite(r2):
        r2 = np.nan
    print(f"{col}: MAE={mae:.4f}, R虏={r2:.4f}" if not np.isnan(r2) else f"{col}: MAE={mae:.4f}, R虏=nan (varianza ~0)")


print(f"\nMSE Global: {mse_global:.4f}")
print(f"R虏 Global: {r2_global:.4f}")

# ===============================================
# M茅tricas normalizadas (MAE relativo %)
# ===============================================
ranges = {
    'cBA_0': (0.5, 3.0),
    'cAIBN_0': (0.0025, 0.02),
    'temp': (60, 80),
    'time': (0, 3600)
}

mae_relativo = {}
for i, col in enumerate(Y.columns):
    r_min, r_max = ranges[col]
    mae_relativo[col] = 100 * mae_vars[i] / (r_max - r_min)
    print(f"{col}: MAE relativo = {mae_relativo[col]:.2f}%")

# ===============================================
# Visualizaci贸n: P茅rdida del entrenamiento
# ===============================================
plt.figure(figsize=(7,4))
plt.plot(history.history['loss'], label='Entrenamiento')
plt.plot(history.history['val_loss'], label='Validaci贸n')
plt.title('Evoluci贸n del error (MSE)')
plt.xlabel('pocas')
plt.ylabel('MSE')
plt.legend()
plt.tight_layout()
plt.show()

# ===============================================
# Comparaci贸n visual: Predicciones vs. Valores reales
# ===============================================
for i, col in enumerate(Y.columns):
    plt.figure(figsize=(5,4))
    plt.scatter(Y_test_descaled[:, i], Y_pred[:, i], alpha=0.6)
    plt.plot([Y_test_descaled[:, i].min(), Y_test_descaled[:, i].max()],
             [Y_test_descaled[:, i].min(), Y_test_descaled[:, i].max()],
             'r--', lw=2)
    plt.title(f"Predicci贸n vs Real - {col}")
    plt.xlabel("Valor real")
    plt.ylabel("Predicci贸n")
    plt.tight_layout()
    plt.show()

# ===============================================
# Visualizaci贸n MMD vs Receta (ejemplo individual)
# ===============================================
idx = 5  # 铆ndice de ejemplo
mmd_curve = X_test[idx, -100:]  # las 100 煤ltimas columnas son MMD
Y_real = Y_test_descaled[idx]
Y_predic = Y_pred[idx]

plt.figure(figsize=(7,4))
plt.plot(range(1, 101), mmd_curve, label="Curva MMD (input)", color="gray")
plt.title("Ejemplo de curva MMD usada como input")
plt.xlabel("Punto de la distribuci贸n (i)")
plt.ylabel("Frecuencia relativa")
plt.legend()
plt.tight_layout()
plt.show()

resultado = pd.DataFrame({
    'Par谩metro': Y.columns,
    'Real': Y_real,
    'Predicho': Y_predic
})
print("\nEjemplo de receta real vs predicha:")
print(resultado)